{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def replace_titles(x):\n",
    "    title=x['title']\n",
    "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n",
    "        return 'Mr'\n",
    "    elif title in ['Countess', 'Mme']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "def clean_df(df, verbose=False):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df, columns = [\"pclass\", \"name\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"cabin\", \"embarked\"])\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Drop \"boat\", \"body\", \"home.dest\" and \"ticket\". The first two hold information if the passenger survived (boat) or if it didn't and the body was recovered (body).\n",
    "    ### Why is this not working??\n",
    "    try:\n",
    "        df = df.drop([\"boat\", \"body\", \"home.dest\", \"ticket\"], axis=1)\n",
    "    except KeyError:\n",
    "        if verbose:\n",
    "            print(\"Any of these features are not in the dataframe: boat, body, home.dest, ticket\")\n",
    "\n",
    "    # Just a few observations, drop them\n",
    "    df = df.drop(df[(pd.isnull(df[\"embarked\"]))].index)\n",
    "\n",
    "    # Replace NULL with median\n",
    "    df[\"fare\"] = df[\"fare\"].fillna(df[\"fare\"].median())\n",
    "    df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "    # from: https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\n",
    "\n",
    "    # Extract titles\n",
    "    df[\"title\"] = df[\"name\"].str.extract(r'(Mrs|Mr|Master|Miss|Major|Rev|Dr|Ms|Mlle|Col|Capt|Mme|Countess|Don|Jonkheer)')\n",
    "    df['title']=df.apply(replace_titles, axis=1)\n",
    "    df = df.drop(\"name\", axis=1)\n",
    "\n",
    "    # Extract Deck\n",
    "    df['deck'] = df[\"cabin\"].str[0].fillna(\"Unknown\")\n",
    "    df = df.drop(\"cabin\", axis=1)\n",
    "\n",
    "    # Create new family_size column\n",
    "    df['family_size'] = df['sibsp']+df['parch'] + 1 #counting the passenger itself\n",
    "    df['fare_per_person'] = df['fare']/df['family_size']\n",
    "    df['alone'] = df['family_size'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "    # Because why not\n",
    "    df['age*class'] = df['age']*df['pclass']\n",
    "####################################### TEST BENCHMARK #######################################\n",
    "    # dummy categories: \"sex\", \"embarked\", \"title\", \"deck\"\n",
    "    sex = [\"male\", \"female\"]\n",
    "    embarked = [\"S\", \"C\", \"Q\"]\n",
    "    title = [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]\n",
    "    deck = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"Unknown\"]    \n",
    "\n",
    "    df[\"sex\"] = df[\"sex\"].astype(pd.CategoricalDtype(sex))\n",
    "    df[\"embarked\"] = df[\"embarked\"].astype(pd.CategoricalDtype(embarked))\n",
    "    df[\"title\"] = df[\"title\"].astype(pd.CategoricalDtype(title))\n",
    "    df[\"deck\"] = df[\"deck\"].astype(pd.CategoricalDtype(deck))\n",
    "###############################################################################################\n",
    "\n",
    "    # Create final dataframe with dummies\n",
    "    df2 = pd.get_dummies(df, columns=[\"sex\", \"embarked\", \"title\", \"deck\"], prefix=\"dummy\")\n",
    "\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "df = pd.read_csv(\"../dataset/titanic_data.csv\")\n",
    "df2 = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and transform input\n",
    "sc = StandardScaler()\n",
    "\n",
    "X = df2.drop([\"survived\"], axis=1)\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)\n",
    "\n",
    "y = df2[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "best_params_rfc = {'bootstrap': True,\n",
    "                   'max_depth': 25,\n",
    "                   'max_features': 'auto',\n",
    "                   'min_samples_leaf': 4,\n",
    "                   'min_samples_split': 10,\n",
    "                   'n_estimators': 40}\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,\n",
    "                             bootstrap=best_params_rfc[\"bootstrap\"],\n",
    "                             max_depth=best_params_rfc[\"max_depth\"],\n",
    "                             max_features=best_params_rfc[ \"max_features\"],\n",
    "                             min_samples_leaf=best_params_rfc[\"min_samples_leaf\"],\n",
    "                             min_samples_split=best_params_rfc[\"min_samples_split\"],\n",
    "                             n_estimators=best_params_rfc[ \"n_estimators\"])\n",
    "\n",
    "best_params_lr = {'C': 0.01,\n",
    "                  'class_weight': 'None',\n",
    "                  'fit_intercept': True,\n",
    "                  'max_iter': 50,\n",
    "                  'penalty': 'l2'}\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1,\n",
    "                       C=best_params_lr[\"C\"],\n",
    "                       class_weight=best_params_lr[\"class_weight\"],\n",
    "                       fit_intercept=best_params_lr[\"fit_intercept\"],\n",
    "                       max_iter=best_params_lr[\"max_iter\"],\n",
    "                       penalty=best_params_lr[\"penalty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Voting Classifier Production\n",
    "\n",
    "estimators = [(\"Gaussian Naive Bayes\", gnb),\n",
    "              (\"Random Forest Classifier\", rfc),\n",
    "              (\"Logistic Regression\", lr),\n",
    "              (\"Support Vector Classifier\", svc)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('StandardScaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('model',\n",
       "                 VotingClassifier(estimators=[('Gaussian Naive Bayes',\n",
       "                                               GaussianNB(priors=None,\n",
       "                                                          var_smoothing=1e-09)),\n",
       "                                              ('Random Forest Classifier',\n",
       "                                               RandomForestClassifier(bootstrap=True,\n",
       "                                                                      ccp_alpha=0.0,\n",
       "                                                                      class_weight=None,\n",
       "                                                                      criterion='gini',\n",
       "                                                                      max_depth=25,\n",
       "                                                                      max_features='aut...\n",
       "                                                                  warm_start=False)),\n",
       "                                              ('Support Vector Classifier',\n",
       "                                               SVC(C=1.0, break_ties=False,\n",
       "                                                   cache_size=200,\n",
       "                                                   class_weight=None, coef0=0.0,\n",
       "                                                   decision_function_shape='ovr',\n",
       "                                                   degree=3, gamma='scale',\n",
       "                                                   kernel='rbf', max_iter=-1,\n",
       "                                                   probability=True,\n",
       "                                                   random_state=None,\n",
       "                                                   shrinking=True, tol=0.001,\n",
       "                                                   verbose=False))],\n",
       "                                  flatten_transform=True, n_jobs=None,\n",
       "                                  voting='soft', weights=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the stages of the pipeline\n",
    "\n",
    "### PIPELINE A\n",
    "\n",
    "pipeline = Pipeline(steps= [('StandardScaler', StandardScaler()),\n",
    "                            ('model', VotingClassifier(estimators=estimators, voting='soft'))])\n",
    "\n",
    "# fit the pipeline model with the training data                            \n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5501180117967508"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[7][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5501180117967508"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.transform([df2.drop(\"survived\", axis=1).iloc[7].values])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [1, 39, 0, 0, 0, 1, 0, 1, 39.0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5501180117967508"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.transform([obs])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc2 = load(\"../modelling/outcomes/scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5501180117967508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc2.transform([obs])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = load('./pipeline_model/titanic_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([df2.drop(\"survived\", axis=1).iloc[6].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([X[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"survived\"].iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass              1.00000\n",
       "age                63.00000\n",
       "sibsp               1.00000\n",
       "parch               0.00000\n",
       "fare               77.95830\n",
       "family_size         2.00000\n",
       "fare_per_person    38.97915\n",
       "alone               0.00000\n",
       "age*class          63.00000\n",
       "dummy_male          0.00000\n",
       "dummy_female        1.00000\n",
       "dummy_S             1.00000\n",
       "dummy_C             0.00000\n",
       "dummy_Q             0.00000\n",
       "dummy_Mr            0.00000\n",
       "dummy_Mrs           0.00000\n",
       "dummy_Miss          1.00000\n",
       "dummy_Master        0.00000\n",
       "dummy_A             0.00000\n",
       "dummy_B             0.00000\n",
       "dummy_C             0.00000\n",
       "dummy_D             1.00000\n",
       "dummy_E             0.00000\n",
       "dummy_F             0.00000\n",
       "dummy_G             0.00000\n",
       "dummy_T             0.00000\n",
       "dummy_Unknown       0.00000\n",
       "Name: 6, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.drop(\"survived\", axis=1).iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
