{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_titles(x):\n",
    "    title=x['title']\n",
    "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n",
    "        return 'Mr'\n",
    "    elif title in ['Countess', 'Mme']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "def clean_df(df, verbose=False):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df, columns = [\"pclass\", \"name\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"cabin\", \"embarked\"])\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Drop \"boat\", \"body\", \"home.dest\" and \"ticket\". The first two hold information if the passenger survived (boat) or if it didn't and the body was recovered (body).\n",
    "    ### Why is this not working??\n",
    "    try:\n",
    "        df = df.drop([\"boat\", \"body\", \"home.dest\", \"ticket\"], axis=1)\n",
    "    except KeyError:\n",
    "        if verbose:\n",
    "            print(\"Any of these features are not in the dataframe: boat, body, home.dest, ticket\")\n",
    "\n",
    "    # Just a few observations, drop them\n",
    "    df = df.drop(df[(pd.isnull(df[\"embarked\"]))].index)\n",
    "\n",
    "    # Replace NULL with median\n",
    "    df[\"fare\"] = df[\"fare\"].fillna(df[\"fare\"].median())\n",
    "    df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "    # from: https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\n",
    "\n",
    "    # Extract titles\n",
    "    df[\"title\"] = df[\"name\"].str.extract(r'(Mrs|Mr|Master|Miss|Major|Rev|Dr|Ms|Mlle|Col|Capt|Mme|Countess|Don|Jonkheer)')\n",
    "    df['title']=df.apply(replace_titles, axis=1)\n",
    "    df = df.drop(\"name\", axis=1)\n",
    "\n",
    "    # Extract Deck\n",
    "    df['deck'] = df[\"cabin\"].str[0].fillna(\"Unknown\")\n",
    "    df = df.drop(\"cabin\", axis=1)\n",
    "\n",
    "    # Create new family_size column\n",
    "    df['family_size'] = df['sibsp']+df['parch'] + 1 #counting the passenger itself\n",
    "    df['fare_per_person'] = df['fare']/df['family_size']\n",
    "    df['alone'] = df['family_size'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "    # Because why not\n",
    "    df['age*class'] = df['age']*df['pclass']\n",
    "####################################### TEST BENCHMARK #######################################\n",
    "    # dummy categories: \"sex\", \"embarked\", \"title\", \"deck\"\n",
    "    sex = [\"male\", \"female\"]\n",
    "    embarked = [\"S\", \"C\", \"Q\"]\n",
    "    title = [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]\n",
    "    deck = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"Unknown\"]    \n",
    "\n",
    "    df[\"sex\"] = df[\"sex\"].astype(pd.CategoricalDtype(sex))\n",
    "    df[\"embarked\"] = df[\"embarked\"].astype(pd.CategoricalDtype(embarked))\n",
    "    df[\"title\"] = df[\"title\"].astype(pd.CategoricalDtype(title))\n",
    "    df[\"deck\"] = df[\"deck\"].astype(pd.CategoricalDtype(deck))\n",
    "###############################################################################################\n",
    "\n",
    "    # Create final dataframe with dummies\n",
    "    df2 = pd.get_dummies(df, columns=[\"sex\", \"embarked\", \"title\", \"deck\"], prefix=\"dummy\")\n",
    "\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "df = pd.read_csv(\"../dataset/titanic_data.csv\")\n",
    "#df2 = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f71f8924582f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"survived\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"boat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"body\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"home.dest\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ticket\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# Split and transform input\n",
    "sc = StandardScaler()\n",
    "\n",
    "X = df2.drop([\"survived\", \"boat\", \"body\", \"home.dest\", \"ticket\"], axis=1)\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)\n",
    "\n",
    "y = df2[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "best_params_rfc = {'bootstrap': True,\n",
    "                   'max_depth': 25,\n",
    "                   'max_features': 'auto',\n",
    "                   'min_samples_leaf': 4,\n",
    "                   'min_samples_split': 10,\n",
    "                   'n_estimators': 40}\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,\n",
    "                             bootstrap=best_params_rfc[\"bootstrap\"],\n",
    "                             max_depth=best_params_rfc[\"max_depth\"],\n",
    "                             max_features=best_params_rfc[ \"max_features\"],\n",
    "                             min_samples_leaf=best_params_rfc[\"min_samples_leaf\"],\n",
    "                             min_samples_split=best_params_rfc[\"min_samples_split\"],\n",
    "                             n_estimators=best_params_rfc[ \"n_estimators\"])\n",
    "\n",
    "best_params_lr = {'C': 0.01,\n",
    "                  'class_weight': 'None',\n",
    "                  'fit_intercept': True,\n",
    "                  'max_iter': 50,\n",
    "                  'penalty': 'l2'}\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1,\n",
    "                       C=best_params_lr[\"C\"],\n",
    "                       class_weight=best_params_lr[\"class_weight\"],\n",
    "                       fit_intercept=best_params_lr[\"fit_intercept\"],\n",
    "                       max_iter=best_params_lr[\"max_iter\"],\n",
    "                       penalty=best_params_lr[\"penalty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier Production\n",
    "\n",
    "estimators = [(\"Gaussian Naive Bayes\", gnb),\n",
    "              (\"Random Forest Classifier\", rfc),\n",
    "              (\"Logistic Regression\", lr),\n",
    "              (\"Support Vector Classifier\", svc)]\n",
    "\n",
    "#vc_prod = VotingClassifier(estimators=estimators, voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('StandardScaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('model',\n",
       "                 VotingClassifier(estimators=[('Gaussian Naive Bayes',\n",
       "                                               GaussianNB(priors=None,\n",
       "                                                          var_smoothing=1e-09)),\n",
       "                                              ('Random Forest Classifier',\n",
       "                                               RandomForestClassifier(bootstrap=True,\n",
       "                                                                      ccp_alpha=0.0,\n",
       "                                                                      class_weight=None,\n",
       "                                                                      criterion='gini',\n",
       "                                                                      max_depth=25,\n",
       "                                                                      max_features='aut...\n",
       "                                                                  warm_start=False)),\n",
       "                                              ('Support Vector Classifier',\n",
       "                                               SVC(C=1.0, break_ties=False,\n",
       "                                                   cache_size=200,\n",
       "                                                   class_weight=None, coef0=0.0,\n",
       "                                                   decision_function_shape='ovr',\n",
       "                                                   degree=3, gamma='scale',\n",
       "                                                   kernel='rbf', max_iter=-1,\n",
       "                                                   probability=True,\n",
       "                                                   random_state=None,\n",
       "                                                   shrinking=True, tol=0.001,\n",
       "                                                   verbose=False))],\n",
       "                                  flatten_transform=True, n_jobs=None,\n",
       "                                  voting='soft', weights=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the stages of the pipeline\n",
    "\n",
    "### PIPELINE A\n",
    "\n",
    "pipeline = Pipeline(steps= [('StandardScaler', StandardScaler()),\n",
    "                            #('CleanDF', clean_df(x)),\n",
    "                            ('model', VotingClassifier(estimators=estimators, voting='soft'))])\n",
    "\n",
    "# fit the pipeline model with the training data                            \n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-ac8769bf5401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"survived\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m pipeB = Pipeline(steps = [(\"PreProcess\", clean_df(X.values)),\n\u001b[0m\u001b[0;32m      7\u001b[0m                           \u001b[1;33m(\u001b[0m\u001b[1;34m\"StandardScaler\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                           \u001b[1;33m(\u001b[0m\u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\envs\\titanic\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\envs\\titanic\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             if (not (hasattr(t, \"fit\") or hasattr(t, \"fit_transform\")) or not\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\envs\\titanic\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1478\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1479\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "### PIPELINE B\n",
    "\n",
    "X = df.drop([\"survived\", \"boat\", \"body\", \"home.dest\", \"ticket\"], axis=1)\n",
    "y = df[\"survived\"]\n",
    "\n",
    "pipeB = Pipeline(steps = [(\"PreProcess\", clean_df(X.values)),\n",
    "                          (\"StandardScaler\", StandardScaler()),\n",
    "                          (\"Model\", VotingClassifier(estimators=estimators, voting='soft'))\n",
    "                         ])\n",
    "\n",
    "# fit the pipeline model with the training data                            \n",
    "pipeB.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# user_input = [[1, \"Andrews, Mr. Thomas Jr\", \"male\",39.0,0,0,0.0,\"A36\",\"S\"]]\n",
    "\n",
    "# X_input = clean_df(user_input).values\n",
    "\n",
    "# print(pipeline.predict(X_input))\n",
    "# print(df.iloc[i][\"survived\"])\n",
    "\n",
    "# pred = pipeline.predict(X_input)\n",
    "# y = df.iloc[i][\"survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./pipeline_model/titanic_pipeline.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipeline, filename=\"./pipeline_model/titanic_pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass -0.23156540020526195\n",
      "age -0.09291260314186896\n",
      "sibsp -0.19467973450666795\n",
      "parch -0.04156462680125151\n",
      "fare 0.05997498009387026\n",
      "family_size -0.15078079734018335\n",
      "fare_per_person 0.05497008142222499\n",
      "alone -0.09593557494537071\n",
      "age*class -0.200746172837031\n",
      "dummy_male -0.308056186738117\n",
      "dummy_female 0.3080561867381171\n",
      "dummy_S -0.07627704258582577\n",
      "dummy_C 0.10048223124827664\n",
      "dummy_Q -0.019532055572217388\n",
      "dummy_Mr -0.3310382301588715\n",
      "dummy_Mrs 0.23371456272179644\n",
      "dummy_Miss 0.10299936576467876\n",
      "dummy_Master 0.16956775938402702\n",
      "dummy_A 0.020605462010975056\n",
      "dummy_B 0.06154515700276333\n",
      "dummy_C 0.006790457867818288\n",
      "dummy_D 0.08302648247068586\n",
      "dummy_E 0.12419546535999203\n",
      "dummy_F 0.07533874391532254\n",
      "dummy_G -0.026431717625191038\n",
      "dummy_T -0.03571321765514116\n",
      "dummy_Unknown -0.14720359384563173\n"
     ]
    }
   ],
   "source": [
    "for var, coef in zip(list(df2.drop(\"survived\", axis=1).columns), list(lr.coef_[0])):\n",
    "    print(var, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dummy_female       0.157080\n",
       "dummy_male         0.122606\n",
       "dummy_Mr           0.107268\n",
       "age*class          0.104286\n",
       "fare_per_person    0.087265\n",
       "fare               0.082521\n",
       "age                0.057946\n",
       "pclass             0.057525\n",
       "dummy_Mrs          0.042855\n",
       "dummy_Unknown      0.037416\n",
       "family_size        0.033465\n",
       "sibsp              0.028605\n",
       "dummy_Miss         0.021712\n",
       "dummy_S            0.010046\n",
       "parch              0.009407\n",
       "dummy_C            0.009082\n",
       "dummy_Master       0.007188\n",
       "alone              0.006662\n",
       "dummy_E            0.005409\n",
       "dummy_B            0.003016\n",
       "dummy_Q            0.002409\n",
       "dummy_C            0.002387\n",
       "dummy_D            0.002343\n",
       "dummy_A            0.000972\n",
       "dummy_F            0.000466\n",
       "dummy_G            0.000063\n",
       "dummy_T            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(rfc.feature_importances_,index=list(df2.drop(\"survived\", axis=1).columns)).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
