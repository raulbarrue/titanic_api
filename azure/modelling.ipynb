{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('azure-training': conda)",
   "display_name": "Python 3.8.2 64-bit ('azure-training': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f6cc2971799897eb0ca02973c4931246881cb407ba037d98f8a579c2cbf5eea6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-core 1.15.0 (c:\\programdata\\anaconda\\envs\\azure-training\\lib\\site-packages), Requirement.parse('azureml-core~=1.11.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-core 1.15.0 (c:\\programdata\\anaconda\\envs\\azure-training\\lib\\site-packages), Requirement.parse('azureml-core~=1.11.0'), {'azureml-telemetry'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.15.0 (c:\\programdata\\anaconda\\envs\\azure-training\\lib\\site-packages), Requirement.parse('azureml-core~=1.11.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.15.0 (c:\\programdata\\anaconda\\envs\\azure-training\\lib\\site-packages), Requirement.parse('azureml-core~=1.11.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.15.0 (c:\\programdata\\anaconda\\envs\\azure-training\\lib\\site-packages), Requirement.parse('azureml-core~=1.11.0')).\n",
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
      "titanic-ws workspace loaded.\n",
      "workspaceblobstore datastore loaded.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace \n",
    "\n",
    "ws = Workspace(subscription_id=\"fc1c5e68-95c2-4bce-9ff9-5bd8442fb921\", resource_group=\"titanic-api\", workspace_name=\"titanic-ws\")\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "print(ws.name, \"workspace loaded.\")\n",
    "print(default_ds.name, \"datastore loaded.\")"
   ]
  },
  {
   "source": [
    "# Modelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import titanic_functions as tfunc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df2 = pd.read_csv(\"../dataset/titanic_data.csv\")\n",
    "df2 = tfunc.clean_df(df2)\n",
    "\n",
    "X = df2.drop(\"survived\", axis=1)\n",
    "y = df2[\"survived\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Xsc = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in two equal parts\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xsc, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "gnb = GaussianNB()\n",
    "rfc = RandomForestClassifier()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = gnb.fit(X_train, y_train)\n",
    "rfc = rfc.fit(X_train, y_train)\n",
    "lr = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gnb = gnb.predict(X_test)\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Gaussian NB:\n\tAccuracy: 0.7023\n\tPrecision: 0.5897\n\tRecall: 0.8679\n\tF1-Score: 0.7023\n\nRandom Forest Classifier:\n\tAccuracy: 0.7824\n\tPrecision: 0.7379\n\tRecall: 0.717\n\tF1-Score: 0.7273\n\nLogistic Regression:\n\tAccuracy: 0.8282\n\tPrecision: 0.7699\n\tRecall: 0.8208\n\tF1-Score: 0.7945\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, classification_report, f1_score\n",
    "import numpy as np\n",
    "\n",
    "models = {\"Gaussian NB\": pred_gnb, \"Random Forest Classifier\": pred_rfc, \"Logistic Regression\": pred_lr}\n",
    "metrics = {}\n",
    "\n",
    "for name, pred in models.items():\n",
    "    print(name+\":\")\n",
    "\n",
    "    print(\"\\tAccuracy:\", np.round(accuracy_score(y_test, pred),4))\n",
    "    print(\"\\tPrecision:\", np.round(precision_score(y_test, pred),4))\n",
    "    print(\"\\tRecall:\", np.round(recall_score(y_test, pred),4))\n",
    "    print(\"\\tF1-Score:\", np.round(f1_score(y_test, pred),4))\n",
    "    print()\n",
    "\n",
    "    m = {\"Accuracy:\": np.round(accuracy_score(y_test, pred),4),\n",
    "        \"Precision:\": np.round(precision_score(y_test, pred),4),\n",
    "        \"Recall:\": np.round(recall_score(y_test, pred),4),\n",
    "        \"F1-Score:\": np.round(f1_score(y_test, pred),4)}\n",
    "    metrics[name] = m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading model_folder/titanic-api-model.pkl\n",
      "Uploaded model_folder/titanic-api-model.pkl, 1 files out of an estimated total of 2\n",
      "Uploading model_folder/titanic-api-scaler.pkl\n",
      "Uploaded model_folder/titanic-api-scaler.pkl, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_35f9ad56197f496087aaf1f32cab37f5"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "best_model = lr\n",
    "best_model_name = \"Logistic Regression\"\n",
    "best_model_metrics = metrics[best_model_name]\n",
    "\n",
    "os.makedirs(\"model_folder\", exist_ok=True)\n",
    "joblib.dump(best_model, \"model_folder/titanic-api-model.pkl\")\n",
    "joblib.dump(scaler, \"model_folder/titanic-api-scaler.pkl\")\n",
    "\n",
    "default_ds.upload_files([\"model_folder/titanic-api-model.pkl\", \"model_folder/titanic-api-scaler.pkl\"], target_path=\"model_folder\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registering model titanic-api-model\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='titanic-ws', subscription_id='fc1c5e68-95c2-4bce-9ff9-5bd8442fb921', resource_group='titanic-api'), name=titanic-api-model, id=titanic-api-model:8, version=8, tags={'Accuracy:': '0.8282', 'Precision:': '0.7699', 'Recall:': '0.8208', 'F1-Score:': '0.7945'}, properties={})"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "Model.register(ws, \"model_folder/titanic-api-model.pkl\", \"titanic-api-model\", tags=best_model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registering model titanic-api-scaler\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='titanic-ws', subscription_id='fc1c5e68-95c2-4bce-9ff9-5bd8442fb921', resource_group='titanic-api'), name=titanic-api-scaler, id=titanic-api-scaler:5, version=5, tags={'Scaler': 'Titanic Input Scaler'}, properties={})"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "Model.register(ws, \"model_folder/scaler.pkl\", \"titanic-api-scaler\", tags={\"Scaler\":\"Titanic Input Scaler\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model.get_model_path(\"titanic-api-model\")\n",
    "# scaler = Model.get_model_path(\"titanic-api-scaler\")"
   ]
  },
  {
   "source": [
    "# DEPLOYMENT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting model_folder/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_folder/score.py\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global scaler\n",
    "    model_path = './model_folder/titanic-api-model.pkl'\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    scaler_path = './model_folder/titanic-api-scaler.pkl'\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "def run(data):\n",
    "\n",
    "    #ws = Workspace(subscription_id=\"fc1c5e68-95c2-4bce-9ff9-5bd8442fb921\", resource_group=\"titanic-api\", workspace_name=\"titanic-ws\")\n",
    "\n",
    "    try:\n",
    "        data = json.loads(data)['data']\n",
    "        data = scaler.transform([data])\n",
    "        result = model.predict(data)\n",
    "        # You can return any data type, as long as it is JSON serializable.\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deployment\n"
     ]
    }
   ],
   "source": [
    "# Deployment Env\n",
    "\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create an environment and add conda dependencies to it\n",
    "myenv = Environment(name=\"myenv\")\n",
    "# Enable Docker based environment\n",
    "myenv.docker.enabled = True\n",
    "# Build conda dependencies\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn'],\n",
    "                                                           pip_packages=['azureml-defaults'])\n",
    "                                                        \n",
    "print(\"Deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment config\n",
    "# from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "# from azureml.core import Model \n",
    "\n",
    "# model = ws.models[\"titanic-api-model\"]\n",
    "\n",
    "inference_config = InferenceConfig(source_directory=\"model_folder\",\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   environment=myenv)\n",
    "\n",
    "# deploy_config = AciWebservice.deploy_configuration(cpu_cores=0.1, memory_gb=0.5)\n",
    "\n",
    "# service_name = \"titanic-api\"\n",
    "\n",
    "# service = Model.deploy(ws, service_name, [model], inference_config, deploy_config)\n",
    "# service.wait_for_deployment(True)\n",
    "# print(service.state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ENDPOINT\n",
    "endpoint = service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=10\n",
    "\n",
    "x_new = list(df2.drop(\"survived\",axis=1).iloc[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted: The reset parameter is False but there is no n_features_in_ attribute. Is this estimator fitted?\nActual: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted:\", requests.post(endpoint, input_json, headers = headers).json())\n",
    "print(\"Actual:\", df2[\"survived\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'could not convert string to float: \\'{\"data\": [1.0, 47.0, 1.0, 0.0, 227.525, 2.0, 113.7625, 0.0, 47.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\\''"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "requests.post(endpoint, input_json, headers = headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "service = AciWebservice(ws, \"titanic-api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service.update(inference_config=inference_config)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}