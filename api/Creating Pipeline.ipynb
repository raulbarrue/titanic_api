{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_titles(x):\n",
    "    title=x['title']\n",
    "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n",
    "        return 'Mr'\n",
    "    elif title in ['Countess', 'Mme']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "def clean_df(df, verbose=False):\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df, columns = [\"pclass\", \"name\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"cabin\", \"embarked\"])\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Drop \"boat\", \"body\", \"home.dest\" and \"ticket\". The first two hold information if the passenger survived (boat) or if it didn't and the body was recovered (body).\n",
    "    ### Why is this not working??\n",
    "    try:\n",
    "        df = df.drop([\"boat\", \"body\", \"home.dest\", \"ticket\"], axis=1)\n",
    "    except KeyError:\n",
    "        if verbose:\n",
    "            print(\"Any of these features are not in the dataframe: boat, body, home.dest, ticket\")\n",
    "\n",
    "\n",
    "    # Just a few observations, drop them\n",
    "    df = df.drop(df[(pd.isnull(df[\"embarked\"]))].index)\n",
    "\n",
    "    # Replace NULL with median\n",
    "    df[\"fare\"] = df[\"fare\"].fillna(df[\"fare\"].median())\n",
    "    df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "\n",
    "    # from: https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\n",
    "\n",
    "    # Extract titles\n",
    "    df[\"title\"] = df[\"name\"].str.extract(r'(Mrs|Mr|Master|Miss|Major|Rev|Dr|Ms|Mlle|Col|Capt|Mme|Countess|Don|Jonkheer)')\n",
    "    df['title']=df.apply(replace_titles, axis=1)\n",
    "    df = df.drop(\"name\", axis=1)\n",
    "\n",
    "    # Extract Deck\n",
    "    df['deck'] = df[\"cabin\"].str[0].fillna(\"Unknown\")\n",
    "    df = df.drop(\"cabin\", axis=1)\n",
    "\n",
    "    # Create new family_size column\n",
    "    df['family_size'] = df['sibsp']+df['parch'] + 1 #counting the passenger itself\n",
    "    df['fare_per_person'] = df['fare']/df['family_size']\n",
    "    df['alone'] = df['family_size'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "    # Because why not\n",
    "    df['age*class'] = df['age']*df['pclass']\n",
    "\n",
    "####################################### TEST BENCHMARK #######################################\n",
    "    # dummy categories: \"sex\", \"embarked\", \"title\", \"deck\"\n",
    "    sex = [\"male\", \"female\"]\n",
    "    embarked = [\"S\", \"C\", \"Q\"]\n",
    "    title = [\"Mr\", \"Mrs\", \"Miss\", \"Master\"]\n",
    "    deck = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"Unknown\"]    \n",
    "\n",
    "    df[\"sex\"] = df[\"sex\"].astype(pd.CategoricalDtype(sex))\n",
    "    df[\"embarked\"] = df[\"embarked\"].astype(pd.CategoricalDtype(embarked))\n",
    "    df[\"title\"] = df[\"title\"].astype(pd.CategoricalDtype(title))\n",
    "    df[\"deck\"] = df[\"deck\"].astype(pd.CategoricalDtype(deck))\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "    # Create final dataframe with dummies\n",
    "    df2 = pd.get_dummies(df, columns=[\"sex\", \"embarked\", \"title\", \"deck\"], prefix=\"dummy\")\n",
    "\n",
    "\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "df = pd.read_csv(\"../dataset/titanic_data.csv\")\n",
    "df2 = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and transform input\n",
    "sc = StandardScaler()\n",
    "\n",
    "X = df2.drop(\"survived\", axis=1)\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)\n",
    "\n",
    "y = df2[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "best_params_rfc = {'bootstrap': True,\n",
    "                   'max_depth': 25,\n",
    "                   'max_features': 'auto',\n",
    "                   'min_samples_leaf': 4,\n",
    "                   'min_samples_split': 10,\n",
    "                   'n_estimators': 40}\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,\n",
    "                             bootstrap=best_params_rfc[\"bootstrap\"],\n",
    "                             max_depth=best_params_rfc[\"max_depth\"],\n",
    "                             max_features=best_params_rfc[ \"max_features\"],\n",
    "                             min_samples_leaf=best_params_rfc[\"min_samples_leaf\"],\n",
    "                             min_samples_split=best_params_rfc[\"min_samples_split\"],\n",
    "                             n_estimators=best_params_rfc[ \"n_estimators\"])\n",
    "\n",
    "best_params_lr = {'C': 0.01,\n",
    "                  'class_weight': 'None',\n",
    "                  'fit_intercept': True,\n",
    "                  'max_iter': 50,\n",
    "                  'penalty': 'l2'}\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1,\n",
    "                       C=best_params_lr[\"C\"],\n",
    "                       class_weight=best_params_lr[\"class_weight\"],\n",
    "                       fit_intercept=best_params_lr[\"fit_intercept\"],\n",
    "                       max_iter=best_params_lr[\"max_iter\"],\n",
    "                       penalty=best_params_lr[\"penalty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier Production\n",
    "\n",
    "estimators = [(\"Gaussian Naive Bayes\", gnb),\n",
    "              (\"Random Forest Classifier\", rfc),\n",
    "              (\"Logistic Regression\", lr),\n",
    "              (\"Support Vector Classifier\", svc)]\n",
    "\n",
    "#vc_prod = VotingClassifier(estimators=estimators, voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('StandardScaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('model',\n",
       "                 VotingClassifier(estimators=[('Gaussian Naive Bayes',\n",
       "                                               GaussianNB(priors=None,\n",
       "                                                          var_smoothing=1e-09)),\n",
       "                                              ('Random Forest Classifier',\n",
       "                                               RandomForestClassifier(bootstrap=True,\n",
       "                                                                      ccp_alpha=0.0,\n",
       "                                                                      class_weight=None,\n",
       "                                                                      criterion='gini',\n",
       "                                                                      max_depth=25,\n",
       "                                                                      max_features='aut...\n",
       "                                                                  warm_start=False)),\n",
       "                                              ('Support Vector Classifier',\n",
       "                                               SVC(C=1.0, break_ties=False,\n",
       "                                                   cache_size=200,\n",
       "                                                   class_weight=None, coef0=0.0,\n",
       "                                                   decision_function_shape='ovr',\n",
       "                                                   degree=3, gamma='scale',\n",
       "                                                   kernel='rbf', max_iter=-1,\n",
       "                                                   probability=True,\n",
       "                                                   random_state=None,\n",
       "                                                   shrinking=True, tol=0.001,\n",
       "                                                   verbose=False))],\n",
       "                                  flatten_transform=True, n_jobs=None,\n",
       "                                  voting='soft', weights=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the stages of the pipeline\n",
    "pipeline = Pipeline(steps= [('StandardScaler', StandardScaler()),\n",
    "                            #('CleanDF', clean_df(x)),\n",
    "                            ('model', VotingClassifier(estimators=estimators, voting='soft'))])\n",
    "\n",
    "# fit the pipeline model with the training data                            \n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# user_input = [[1, \"Andrews, Mr. Thomas Jr\", \"male\",39.0,0,0,0.0,\"A36\",\"S\"]]\n",
    "\n",
    "# X_input = clean_df(user_input).values\n",
    "\n",
    "# print(pipeline.predict(X_input))\n",
    "# print(df.iloc[i][\"survived\"])\n",
    "\n",
    "# pred = pipeline.predict(X_input)\n",
    "# y = df.iloc[i][\"survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./pipeline_model/titanic_pipeline.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipeline, filename=\"./pipeline_model/titanic_pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
